{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUIA - TFM - RECEIPT - Ticket .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "18T0xmgtAqEq",
        "sFbNfxeTFB4S",
        "arGVyCx2Qg_4"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1g5JEIymyEdpeBPA0Nct5b4td6GJYcP9G",
      "authorship_tag": "ABX9TyOw/GLk5IqphoglE46Id3YX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejas/Ticket-Entity-Recognizer---AI-Master-s-thesis/blob/master/MUIA_TFM_RECEIPT_Ticket_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFudwyValmog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5ZBC1gTAGFe",
        "colab_type": "text"
      },
      "source": [
        "# Receipts Recognizer\n",
        "- Author: Antonio Sejas\n",
        "- UPM - MUIA - TFM\n",
        "- License: MIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F64AZpDnmm-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum\n",
        "class ShopType(Enum):\n",
        "  retailer = 'retailer'\n",
        "  restaurant = 'restaurant'\n",
        "  supermarket = 'supermarket'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8TNQNaknTg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18T0xmgtAqEq",
        "colab_type": "text"
      },
      "source": [
        "## OCRs\n",
        "\n",
        "### Keras OCR\n",
        "pip install keras-ocr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFn2y9I0Bnqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca036b7a-2871-46ca-c698-c7a336bc4c34"
      },
      "source": [
        "cd /content/drive/My\\ Drive/proyectos/ai/receipts-recognizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/proyectos/ai/receipts-recognizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uLkw3H1_zxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "d54da32d-a3ff-4dfa-dfbc-f2957ba3b37d"
      },
      "source": [
        "!pip install keras-ocr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-ocr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/72/c93a239e6cb6c6d604054c6d418f368338c2e23f83882600cbd5a888cc91/keras-ocr-0.8.4.tar.gz (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 9.1MB/s \n",
            "\u001b[?25hCollecting essential_generators\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/b1/979b823497488e5f13c9070fcd6a2e24f6d9c6fd5398e0fbeccc8158bd3b/essential_generators-0.9.2-py3-none-any.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-ocr) (4.41.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from keras-ocr) (0.2.9)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Collecting fonttools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/89/932dc9478aae3c74f80f1cb390064fd4620d791e7f98b705160551e0ea39/fonttools-4.14.0-py3-none-any.whl (811kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 64.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from keras-ocr) (0.5.3)\n",
            "Collecting pyclipper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/82/eb4d65b8a7f53e83157d54b200c97e1d2085e48664f6f41af49155f6f9dd/pyclipper-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 61.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from keras-ocr) (1.7.1)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug->keras-ocr) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->keras-ocr) (4.4.2)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->keras-ocr) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->keras-ocr) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->keras-ocr) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug->keras-ocr) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug->keras-ocr) (2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (2.10.0)\n",
            "Building wheels for collected packages: keras-ocr\n",
            "  Building wheel for keras-ocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-ocr: filename=keras_ocr-0.8.4-cp36-none-any.whl size=148640 sha256=7f7ce50143f57cf2aed24f8585d989d26189c7cd9d4b7e5066a9dc546d7aa74f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/4b/03/a9bf717ffaae60b05c9bdbe05cb16854aa5b83188e046c72a3\n",
            "Successfully built keras-ocr\n",
            "Installing collected packages: essential-generators, validators, fonttools, pyclipper, keras-applications, efficientnet, keras-ocr\n",
            "Successfully installed efficientnet-1.0.0 essential-generators-0.9.2 fonttools-4.14.0 keras-applications-1.0.8 keras-ocr-0.8.4 pyclipper-1.2.0 validators-0.18.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERX7TKH6FcCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_paths_list = [\n",
        "      './dataset/retailer/retailer-benetton.jpg',\n",
        "      './dataset/retailer/retailer-benetton-2.jpg',\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uxfXIPGAvT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "b7f683a9-b594-4546-a844-96544e0d85c7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import keras_ocr\n",
        "\n",
        "pipeline = keras_ocr.pipeline.Pipeline()\n",
        "images = [\n",
        "    keras_ocr.tools.read(path) for path in images_paths_list\n",
        "]\n",
        "\n",
        "# predictions list of (word, box) tuples.\n",
        "prediction_groups = pipeline.recognize(images)\n",
        "print(prediction_groups)\n",
        "\n",
        "# Plot the predictions\n",
        "fig, axs = plt.subplots(nrows=len(images), figsize=(40, 40))\n",
        "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
        "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-56eb70a333ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m images = [\n\u001b[1;32m      6\u001b[0m     \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_paths_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecognizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mrecognizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights, load_from_torch, optimizer, backbone_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m             weights_path = tools.download_and_verify(url=weights_config['url'],\n\u001b[1;32m    604\u001b[0m                                                      \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                                                      sha256=weights_config['sha256'])\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/tools.py\u001b[0m in \u001b[0;36mdownload_and_verify\u001b[0;34m(url, sha256, cache_dir, verbose, filename)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0msha256\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msha256\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msha256sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Error occurred verifying sha256.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Error occurred verifying sha256."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFbNfxeTFB4S",
        "colab_type": "text"
      },
      "source": [
        "### Pytesseract OCR\n",
        "pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vPEe_BpBYkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_KAXoYFFN0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytesseract\n",
        "import cv2\n",
        "\n",
        "def image_path_to_text(image_path:str) -> str:\n",
        "  try:\n",
        "    img = cv2.imread(images_paths_list[1])\n",
        "    return pytesseract.image_to_string(img)\n",
        "  except Exception:\n",
        "    print('failed: '+image_path)\n",
        "    return ''\n",
        "\n",
        "receipt_texts_list = []\n",
        "for image_path in images_paths_list:\n",
        "  print('image_path',image_path)\n",
        "  receipt_texts_list.append(image_path_to_text(image_path))\n",
        "\n",
        "print(receipt_texts_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGVyCx2Qg_4",
        "colab_type": "text"
      },
      "source": [
        "## Spacy POS and NER\n",
        "The performance is very low.\n",
        "We cannot extract any result from this response.\n",
        "Spacy doesn't perform well in this context of spanish and receipts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESskACokMCDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmXeoecsIMog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import es_core_news_sm\n",
        "nlp = es_core_news_sm.load()\n",
        "doc  = nlp(receipt_texts_list[0])\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jQHdgo-Kf3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.label,ent.label_, ent.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAI3K_amPEnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSvsQtnjt6ey",
        "colab_type": "text"
      },
      "source": [
        "## My own specific NER Tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Io3n3pcsuk",
        "colab_type": "text"
      },
      "source": [
        "### Generator of tickets and tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiarvsRtyMSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1qgMkbcU5P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attribute:\n",
        "  def __init__(self, code='', value='', accuracy=0.0):\n",
        "    self.code = code\n",
        "    self.value = value\n",
        "    self.accuracy = accuracy\n",
        "\n",
        "class Receipt:\n",
        "  trade_name = Attribute(code='TRADE_NAME')\n",
        "  name = Attribute(code='NAME')\n",
        "  address = Attribute(code='ADDR')\n",
        "  phone = Attribute(code='PHONE')\n",
        "  receipt_number = Attribute(code='RNUMBER')\n",
        "  date = Attribute(code='DATE')\n",
        "  total = Attribute(code='TOTAL')\n",
        "  tax = Attribute(code='TAX')\n",
        "  rate = Attribute(code='RATE')\n",
        "  fiscal_id = Attribute(code='FISCAL_ID')\n",
        "  \n",
        "  @classmethod\n",
        "  def _props(cls):   \n",
        "    return [key for key in cls.__dict__.keys() if key[0] != '_']\n",
        "  \n",
        "  @classmethod\n",
        "  def _prop_codes(cls):   \n",
        "    return [getattr(cls, key).code for key in cls._props()]\n",
        "\n",
        "# Products for future developments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Fuhoq3hKr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "43354139-0eb8-4bd7-df73-895594ecdf0c"
      },
      "source": [
        "def add_prefix_to_list(output_list:str)->str:\n",
        "  biluo = ['B', 'I', 'L', 'U', 'O'] # Begin, In, Last, Unit, Outside\n",
        "  new_output = []\n",
        "  for word in output_list:\n",
        "    for prefix in biluo:\n",
        "      new_output.append(prefix+'-'+word)\n",
        "  return new_output\n",
        "\n",
        "OUTPUTS = add_prefix_to_list(Receipt._prop_codes())+['O', 'SEP']\n",
        "OUTPUTS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-TRADE_NAME',\n",
              " 'I-TRADE_NAME',\n",
              " 'L-TRADE_NAME',\n",
              " 'U-TRADE_NAME',\n",
              " 'O-TRADE_NAME',\n",
              " 'B-NAME',\n",
              " 'I-NAME',\n",
              " 'L-NAME',\n",
              " 'U-NAME',\n",
              " 'O-NAME',\n",
              " 'B-ADDR',\n",
              " 'I-ADDR',\n",
              " 'L-ADDR',\n",
              " 'U-ADDR',\n",
              " 'O-ADDR',\n",
              " 'B-PHONE',\n",
              " 'I-PHONE',\n",
              " 'L-PHONE',\n",
              " 'U-PHONE',\n",
              " 'O-PHONE',\n",
              " 'B-RNUMBER',\n",
              " 'I-RNUMBER',\n",
              " 'L-RNUMBER',\n",
              " 'U-RNUMBER',\n",
              " 'O-RNUMBER',\n",
              " 'B-DATE',\n",
              " 'I-DATE',\n",
              " 'L-DATE',\n",
              " 'U-DATE',\n",
              " 'O-DATE',\n",
              " 'B-TOTAL',\n",
              " 'I-TOTAL',\n",
              " 'L-TOTAL',\n",
              " 'U-TOTAL',\n",
              " 'O-TOTAL',\n",
              " 'B-TAX',\n",
              " 'I-TAX',\n",
              " 'L-TAX',\n",
              " 'U-TAX',\n",
              " 'O-TAX',\n",
              " 'B-RATE',\n",
              " 'I-RATE',\n",
              " 'L-RATE',\n",
              " 'U-RATE',\n",
              " 'O-RATE',\n",
              " 'B-FISCAL_ID',\n",
              " 'I-FISCAL_ID',\n",
              " 'L-FISCAL_ID',\n",
              " 'U-FISCAL_ID',\n",
              " 'O-FISCAL_ID',\n",
              " 'O',\n",
              " 'SEP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16u1P4R_t61Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum\n",
        "class FakeType(Enum):\n",
        "  fiscal_id = 'fiscal_id'\n",
        "  trade_name = 'trade_name'\n",
        "  name = 'name'\n",
        "  address = 'address'\n",
        "  phone = 'phone'\n",
        "  subtotal = 'subtotal'\n",
        "  total = 'total'\n",
        "  ticket_number = 'ticket_number'\n",
        "  tax_rate = 'tax_rate'\n",
        "class Faker:\n",
        "\n",
        "  of = ''\n",
        "  def __init__(self, of:FakeType):\n",
        "    self.of = of\n",
        "    if self.of == FakeType.fiscal_id:\n",
        "      return 'B38103792'\n",
        "    elif self.of == FakeType.trade_name:\n",
        "      return 'UNITED COLOR OF BENETTON'\n",
        "    elif self.of == FakeType.name:\n",
        "      return 'RAZZIA SL'\n",
        "    elif self.of == FakeType.address:\n",
        "      return 'C/. Mesa y Lopez 12'\n",
        "    elif self.of == FakeType.phone:\n",
        "      return '928 22 97 50'\n",
        "    elif self.of == FakeType.subtotal:\n",
        "      return ''\n",
        "    elif self.of == FakeType.total:\n",
        "      return ''\n",
        "    elif self.of == FakeType.ticket_number:\n",
        "      return '36 8390T'\n",
        "    elif self.of == FakeType.tax_rate:\n",
        "      return ''\n",
        "\n",
        "class TicketGenerator:\n",
        "  template = ''\n",
        "  tags = ''\n",
        "\n",
        "  def _sequence(self, text:str, process_sequence)->List[str]:\n",
        "    result = text\n",
        "    for fn in process_sequence:\n",
        "      result = fn(result)\n",
        "    return result\n",
        "  def _replaces(self, text:str)->str:\n",
        "    # generates extra empty lines that later are removed\n",
        "    return text.replace('\\n',' \\n ').replace(':',' : ').replace('.',' . ')\n",
        "  def _remove_stop_tokens(self, tokens_list=[]):\n",
        "    stop_tokens = ['']\n",
        "    return [token for token in tokens_list if token not in stop_tokens]\n",
        "  def _split(self, text:str)->List[str]:\n",
        "    return text.split(' ')\n",
        "  def _lower(self, text:str)->str:\n",
        "    return text.lower()\n",
        "  def _tokenize(self):\n",
        "    process_sequence = [\n",
        "      self._lower,\n",
        "      self._replaces,\n",
        "      self._split,\n",
        "      self._remove_stop_tokens\n",
        "    ]\n",
        "    return self._sequence(self.template.lower(), process_sequence)\n",
        "  def _tags(self):\n",
        "    \"\"\" To be implemented in the subclass \"\"\"\n",
        "    process_sequence = [\n",
        "      self._replaces,\n",
        "      self._split,\n",
        "      self._remove_stop_tokens\n",
        "    ]\n",
        "    return self._sequence(self.tags, process_sequence)\n",
        "  \n",
        "  def generate(self, group_by_pairs=False):\n",
        "    \"\"\" Returns a tuple of tokens, tags\n",
        "    \"\"\"\n",
        "    tokens = self._tokenize()\n",
        "    tags = self._tags()\n",
        "    if len(tokens) == len(tags):\n",
        "      return list(zip(tokens, tags)) if group_by_pairs else (list(tokens), list(tags))\n",
        "    else:\n",
        "      print('ERROR, tokens and tags must have the same len')\n",
        "      return None\n",
        "\n",
        "class SimpleBenettonGenerator(TicketGenerator):\n",
        "  template = \"\"\"<START> UNITED COLOR OF BENETTON\n",
        "RAZZIA SL\n",
        "CIF:B38103792\n",
        "\n",
        "Comercio Minorista\n",
        "C/. Mesa y Lopez 12\n",
        "TLF: 928 22 97 50\n",
        "\n",
        "CAJA: MERCHERIA2\n",
        "\n",
        "FACT. SIMP.: 36 8390T\n",
        "\n",
        "FECHA: 27/07/20\n",
        "\n",
        "HORA: 13:65\n",
        "\n",
        "OPERARIO: OPERARIO1 <END>\"\"\" % ()\n",
        "  tags = \"\"\"START B-NAME I-NAME I-NAME L-NAME\n",
        "B-NAME L-NAME\n",
        "O-FISCAL_ID SEP U-FISCAL_ID\n",
        "\n",
        "O O\n",
        "B-ADDR SEP I-ADDR I-ADDR I-ADDR L-ADDR\n",
        "O-PHONE SEP B-PHONE I-PHONE I-PHONE L-PHONE\n",
        "\n",
        "O SEP O\n",
        "\n",
        "O-RNUMBER  SEP O-RNUMBER SEP SEP B-FICAL_ID L-FISCAL_ID\n",
        "\n",
        "O-DATE SEP U-DATE\n",
        "\n",
        "O SEP O SEP O\n",
        "\n",
        "O SEP O END\"\"\"\n",
        "\n",
        "class BenettonGenerator(TicketGenerator):\n",
        "  template = \"\"\"UNITED COLOR OF BENETTON\n",
        "RAZZIA SL\n",
        "CIF:B38103792\n",
        "\n",
        "Comercio Minorista\n",
        "B-ADDR. Mesa y Lopez 12\n",
        "TLF: 928 22 97 50\n",
        "\n",
        "CAJA: MERCHERIA2\n",
        "\n",
        "FACT. SIMP.: 36 8390T\n",
        "\n",
        "FECHA: 27/07/20\n",
        "\n",
        "HORA: 13:65\n",
        "\n",
        "OPERARIO: OPERARIO1\n",
        "\n",
        "COD DESCRIPCION UND DTO PVP TOTAL\n",
        "N74429 FELPA LETRAS NIÑA 4,99 4,99\n",
        "ZI721IO FELPA+PANTY ALG NINO y 12,99 12,99\n",
        "\n",
        "POLO M/C LISO BASICO\n",
        "218110 ove nino 1 4,99 4,99\n",
        "\n",
        "POLO M/C LISO BASICO\n",
        "216110 our Wino 1 4,99 4,99\n",
        "\n",
        "TOTAL LINEAS: 4\n",
        "TOTAL : 32,96\n",
        "ENTREGA: 32,96\n",
        "CAMBIO: 0,00\n",
        "FORMAS DECOBRO IMPORTE\n",
        "\n",
        "TARJETAS 32,96\n",
        "\n",
        "Gracias por su visita.\n",
        "\n",
        "Los productos son de saldo. Durante los 20 dias\n",
        "naturales siguientes a la compra (excepto ropa\n",
        "interior, bao, fiesta y fantasia) podran ser\n",
        "cambiados por otra prenda © por un vale, siempre\n",
        "que no hayan sido usados, para lo que se precisa la\n",
        "presentacion de la compra. Para realizar cambios y\n",
        "emitir vales de promociones, presentar todas los\n",
        "articulos. Se admiten devoluciones, estas solo\n",
        "podran ser realizadas en la misma tienda de la\n",
        "compra. Garantia comercial adicional segun Texto\n",
        "Refundido de la Ley General para la Defensa de los\n",
        "Consumidores y Usuarios. En caso de reclamacion,\n",
        "puede dirigirse a sugerenclas@razzia es.\n",
        "\n",
        "Puede consultar la informacion sobre Proteccion de\n",
        "Datos en nuestra Pagina web:\n",
        "http: //razzia.avisolegal, jnfo/,\n",
        "\n",
        "We do not accept refund, To change execpt night\n",
        "clothes, underwear, SW/MW8ar) gy Be is Pe raitial\n",
        "the ticket until 19 days\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzioJHsnpysJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dc248032-2fec-492f-b3c8-a0f71248c0ae"
      },
      "source": [
        "words, tags = SimpleBenettonGenerator().generate()\n",
        "print(words)\n",
        "print(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<start>', 'united', 'color', 'of', 'benetton', '\\n', 'razzia', 'sl', '\\n', 'cif', ':', 'b38103792', '\\n', '\\n', 'comercio', 'minorista', '\\n', 'c/', '.', 'mesa', 'y', 'lopez', '12', '\\n', 'tlf', ':', '928', '22', '97', '50', '\\n', '\\n', 'caja', ':', 'mercheria2', '\\n', '\\n', 'fact', '.', 'simp', '.', ':', '36', '8390t', '\\n', '\\n', 'fecha', ':', '27/07/20', '\\n', '\\n', 'hora', ':', '13', ':', '65', '\\n', '\\n', 'operario', ':', 'operario1', '<end>']\n",
            "['START', 'B-NAME', 'I-NAME', 'I-NAME', 'L-NAME', '\\n', 'B-NAME', 'L-NAME', '\\n', 'O-FISCAL_ID', 'SEP', 'U-FISCAL_ID', '\\n', '\\n', 'O', 'O', '\\n', 'B-ADDR', 'SEP', 'I-ADDR', 'I-ADDR', 'I-ADDR', 'L-ADDR', '\\n', 'O-PHONE', 'SEP', 'B-PHONE', 'I-PHONE', 'I-PHONE', 'L-PHONE', '\\n', '\\n', 'O', 'SEP', 'O', '\\n', '\\n', 'O-RNUMBER', 'SEP', 'O-RNUMBER', 'SEP', 'SEP', 'B-FICAL_ID', 'L-FISCAL_ID', '\\n', '\\n', 'O-DATE', 'SEP', 'U-DATE', '\\n', '\\n', 'O', 'SEP', 'O', 'SEP', 'O', '\\n', '\\n', 'O', 'SEP', 'O', 'END']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQDx-IazMKAQ",
        "colab_type": "text"
      },
      "source": [
        "### Create the vocabulary: Index words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muPlZy4trYRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wrods Indexing\n",
        "word_to_ix = {word:ix for ix, word in enumerate(set(words))}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(set(words))}\n",
        "# Tags indexing\n",
        "tag_to_ix = {tag:ix for ix, tag in enumerate(set(tags))}\n",
        "ix_to_tag = {ix:tag for ix, tag in enumerate(set(tags))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcOATEmFm51-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "666395f6-b249-4c13-e499-059a0f560de2"
      },
      "source": [
        "print(tag_to_ix)\n",
        "print(ix_to_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'O-PHONE': 0, 'U-DATE': 1, '\\n': 2, 'O-FISCAL_ID': 3, 'I-NAME': 4, 'O-RNUMBER': 5, 'I-PHONE': 6, 'L-PHONE': 7, 'B-PHONE': 8, 'L-NAME': 9, 'SEP': 10, 'B-ADDR': 11, 'U-FISCAL_ID': 12, 'I-ADDR': 13, 'L-ADDR': 14, 'O': 15, 'L-FISCAL_ID': 16, 'O-DATE': 17, 'END': 18, 'B-NAME': 19, 'START': 20, 'B-FICAL_ID': 21}\n",
            "{0: 'O-PHONE', 1: 'U-DATE', 2: '\\n', 3: 'O-FISCAL_ID', 4: 'I-NAME', 5: 'O-RNUMBER', 6: 'I-PHONE', 7: 'L-PHONE', 8: 'B-PHONE', 9: 'L-NAME', 10: 'SEP', 11: 'B-ADDR', 12: 'U-FISCAL_ID', 13: 'I-ADDR', 14: 'L-ADDR', 15: 'O', 16: 'L-FISCAL_ID', 17: 'O-DATE', 18: 'END', 19: 'B-NAME', 20: 'START', 21: 'B-FICAL_ID'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "689RFxvBgyQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aa03baaf-a033-4c7d-d5eb-5911d077c983"
      },
      "source": [
        "print(word_to_ix)\n",
        "print(ix_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{':': 0, 'hora': 1, '65': 2, 'tlf': 3, '\\n': 4, 'cif': 5, 'lopez': 6, 'mercheria2': 7, '36': 8, 'razzia': 9, 'color': 10, '928': 11, 'of': 12, 'fact': 13, '27/07/20': 14, 'operario1': 15, '8390t': 16, 'fecha': 17, 'caja': 18, 'operario': 19, 'sl': 20, '22': 21, '.': 22, '13': 23, '<end>': 24, 'comercio': 25, '97': 26, 'united': 27, 'c/': 28, 'y': 29, '<start>': 30, '50': 31, 'simp': 32, '12': 33, 'mesa': 34, 'benetton': 35, 'minorista': 36, 'b38103792': 37}\n",
            "{0: ':', 1: 'hora', 2: '65', 3: 'tlf', 4: '\\n', 5: 'cif', 6: 'lopez', 7: 'mercheria2', 8: '36', 9: 'razzia', 10: 'color', 11: '928', 12: 'of', 13: 'fact', 14: '27/07/20', 15: 'operario1', 16: '8390t', 17: 'fecha', 18: 'caja', 19: 'operario', 20: 'sl', 21: '22', 22: '.', 23: '13', 24: '<end>', 25: 'comercio', 26: '97', 27: 'united', 28: 'c/', 29: 'y', 30: '<start>', 31: '50', 32: 'simp', 33: '12', 34: 'mesa', 35: 'benetton', 36: 'minorista', 37: 'b38103792'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puOe8wsPlV8e",
        "colab_type": "text"
      },
      "source": [
        "### Words and Tags encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzBoVKy5k-ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cb0160d-0471-4579-9bcd-6a3a8e96eb31"
      },
      "source": [
        "def hot_encoder_word(size, ix) -> List[int]:\n",
        "  \"\"\" No need to one hot encoding. Because torch indexes the row/column \"\"\"\n",
        "  return [1 if ix == i else 0 for i in range(size)]\n",
        "\n",
        "def _encode_seq(dictionary, seq) -> List[int]:\n",
        "  hot_list = [dictionary[key] for key in seq]\n",
        "  return torch.tensor(hot_list, dtype=torch.long)\n",
        "\n",
        "def word_encoder(seq):\n",
        "  return _encode_seq(dictionary=word_to_ix, seq=seq)\n",
        "\n",
        "def tag_encoder(seq):\n",
        "  return _encode_seq(dictionary=tag_to_ix, seq=seq)\n",
        "\n",
        "print(word_encoder(['hora', 'united', 'benetton']))"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1, 27, 35])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gybZqz6jsBY8",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_5UfhJCINy",
        "colab_type": "text"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaU5oQmsrIYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# reproducible results\n",
        "torch.manual_seed(7)\n",
        "\n",
        "class Lstm(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.lstm(x)[0]\n",
        "        x = self.linear(h)\n",
        "        return x\n",
        "    \n",
        "    def get_states_across_time(self, x):\n",
        "        h_c = None\n",
        "        h_list, c_list = list(), list()\n",
        "        with torch.no_grad():\n",
        "            for t in range(x.size(1)):\n",
        "                h_c = self.lstm(x[:, [t], :], h_c)[1]\n",
        "                h_list.append(h_c[0])\n",
        "                c_list.append(h_c[1])\n",
        "            h = torch.cat(h_list)\n",
        "            c = torch.cat(c_list)\n",
        "        return h, c\n",
        "\n",
        "class LSTM_NER(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUJlF2ECCJ7-",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5QWaBLwAUXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(training_data, input_size, output_size, optimizer, loss_function, epochs=300):\n",
        "  # See what the scores are before training\n",
        "  # Note that element i,j of the output is the score for tag j for word i.\n",
        "  # Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "  with torch.no_grad():\n",
        "      inputs = word_encoder(training_data[0][0])\n",
        "      tag_scores = model(inputs)\n",
        "      print(tag_scores)\n",
        "\n",
        "  for epoch in range(epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "      for sentence, tags in training_data:\n",
        "          # Step 1. Remember that Pytorch accumulates gradients.\n",
        "          # We need to clear them out before each instance\n",
        "          model.zero_grad()\n",
        "\n",
        "          # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "          # Tensors of word indices.\n",
        "          sentence_in = word_encoder(sentence)\n",
        "          targets = tag_encoder(tags)\n",
        "\n",
        "          # Step 3. Run our forward pass.\n",
        "          tag_scores = model(sentence_in)\n",
        "\n",
        "          # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "          #  calling optimizer.step()\n",
        "          loss = loss_function(tag_scores, targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHOy0TLcm6uJ",
        "colab_type": "text"
      },
      "source": [
        "### Tran Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHUU6uLOv8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "aebf086b-0a49-414c-9996-8184e68ece1d"
      },
      "source": [
        "training_data = [(words, tags)]\n",
        "\n",
        "# Setup the LSTM with training settings\n",
        "embedding_dim = 32\n",
        "hidden_dim = 32\n",
        "input_size  = len(word_to_ix)\n",
        "output_size = len(tag_to_ix)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1) # optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "model = LSTM_NER(embedding_dim, hidden_dim, input_size, output_size) # model       = Lstm(input_size, hidden_size, output_size)\n",
        "loss_function = nn.NLLLoss() # criterion   = torch.nn.CrossEntropyLoss() # only accepts one target\n",
        "epochs  = 10\n",
        "\n",
        "# Train the model\n",
        "model = train(training_data, input_size, output_size, optimizer, loss_function, epochs)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-3.3436, -3.1289, -3.2070,  ..., -3.0821, -2.9878, -3.0584],\n",
            "        [-3.1972, -3.1369, -3.2617,  ..., -3.0855, -3.0518, -3.1784],\n",
            "        [-3.1786, -3.0638, -3.2062,  ..., -3.0675, -2.9697, -3.1823],\n",
            "        ...,\n",
            "        [-3.3234, -3.0209, -3.2405,  ..., -3.1183, -2.9928, -3.0963],\n",
            "        [-3.1898, -3.0225, -3.2752,  ..., -3.1920, -3.0296, -3.0548],\n",
            "        [-3.1967, -2.9491, -3.2255,  ..., -3.1978, -3.0319, -3.0848]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFfjB5xYoRMu",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_rIJtkLoTfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Performance:\n",
        "  def __init__(self, correct, total):\n",
        "    self.correct = correct\n",
        "    self.total = total\n",
        "  \n",
        "  @property\n",
        "  def acc(self):\n",
        "    return self.correct/self.total\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f'{self.correct}/{self.total} = {self.acc}'\n",
        "\n",
        "def test(model, testing_data):\n",
        "  batch_predicted = []\n",
        "  batch_scores = []\n",
        "  batch_performance = []\n",
        "  with torch.no_grad():\n",
        "      for receipt, tags  in testing_data:\n",
        "        inputs = word_encoder(receipt)\n",
        "        scores = model(inputs)\n",
        "        predicted_labels = scores.argmax(dim=1)\n",
        "        batch_predicted.append(predicted_labels)\n",
        "        batch_scores.append(scores)\n",
        "        n_correct = (predicted_labels == tag_encoder(tags)).sum().item()\n",
        "        batch_performance.append(Performance(correct=n_correct, total=len(tags)))\n",
        "  return batch_scores, batch_predicted, batch_performance"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmM1WgFocED",
        "colab_type": "text"
      },
      "source": [
        "### Test Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7QdeVA_n-JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4586b2f1-772d-413f-8916-187202cf4648"
      },
      "source": [
        "print(testing_data[0])\n",
        "testing_data = training_data\n",
        "tags_predicted, scores, performances = test(model, testing_data)\n",
        "first_tags_predicted = tags_predicted[0]\n",
        "print(first_tags_predicted) # Get the tags\n",
        "#print(tags_scores[0].softmax(dim=1)) # Get the scores\n",
        "print(performances[0])"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['<start>', 'united', 'color', 'of', 'benetton', '\\n', 'razzia', 'sl', '\\n', 'cif', ':', 'b38103792', '\\n', '\\n', 'comercio', 'minorista', '\\n', 'c/', '.', 'mesa', 'y', 'lopez', '12', '\\n', 'tlf', ':', '928', '22', '97', '50', '\\n', '\\n', 'caja', ':', 'mercheria2', '\\n', '\\n', 'fact', '.', 'simp', '.', ':', '36', '8390t', '\\n', '\\n', 'fecha', ':', '27/07/20', '\\n', '\\n', 'hora', ':', '13', ':', '65', '\\n', '\\n', 'operario', ':', 'operario1', '<end>'], ['START', 'B-NAME', 'I-NAME', 'I-NAME', 'L-NAME', '\\n', 'B-NAME', 'L-NAME', '\\n', 'O-FISCAL_ID', 'SEP', 'U-FISCAL_ID', '\\n', '\\n', 'O', 'O', '\\n', 'B-ADDR', 'SEP', 'I-ADDR', 'I-ADDR', 'I-ADDR', 'L-ADDR', '\\n', 'O-PHONE', 'SEP', 'B-PHONE', 'I-PHONE', 'I-PHONE', 'L-PHONE', '\\n', '\\n', 'O', 'SEP', 'O', '\\n', '\\n', 'O-RNUMBER', 'SEP', 'O-RNUMBER', 'SEP', 'SEP', 'B-FICAL_ID', 'L-FISCAL_ID', '\\n', '\\n', 'O-DATE', 'SEP', 'U-DATE', '\\n', '\\n', 'O', 'SEP', 'O', 'SEP', 'O', '\\n', '\\n', 'O', 'SEP', 'O', 'END'])\n",
            "tensor([[-3.3436, -3.1289, -3.2070,  ..., -3.0821, -2.9878, -3.0584],\n",
            "        [-3.1972, -3.1369, -3.2617,  ..., -3.0855, -3.0518, -3.1784],\n",
            "        [-3.1786, -3.0638, -3.2062,  ..., -3.0675, -2.9697, -3.1823],\n",
            "        ...,\n",
            "        [-3.3234, -3.0209, -3.2405,  ..., -3.1183, -2.9928, -3.0963],\n",
            "        [-3.1898, -3.0225, -3.2752,  ..., -3.1920, -3.0296, -3.0548],\n",
            "        [-3.1967, -2.9491, -3.2255,  ..., -3.1978, -3.0319, -3.0848]])\n",
            "4/62 = 0.06451612903225806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRMmCKYpdjr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}